in---
title: "Business Analytics :: HW2"
author: "[YOUR NAME]"
fontsize: 11pt
output:
  pdf_document: 
    number_sections: yes
---
###MJDOnaldson|MGMT6233|Homework2


# Linear Regression 1 [*Applied*]
```{r eval=FALSE}
exampleDF <- read.csv("C:/Users/Owned/Documents/MGMT6233/Course Data Sets/hw2_ex1.csv") #set for my wd

#load libraries
library(ggplot2)

#Fit data
#example.fit<-lm(x1~x2, data=exampleDF)
#summary(example.fit)
#ydata<-data.frame(exampleDF$y)
#predict(example.fit,ydata)



example2.fit<- lm( y ~ x1 * x2, data=exampleDF)
summary(example2.fit)

#Graph Data
plot(exampleDF$y,exampleDF$x1)
abline(example2.fit)    
abline(example2.fit, lwd=3, col="red") 




#predicting the NA values
testSet<-exampleDF[41:60,]
naPredict<-predict(example.fit,testSet)



```

## Comments and analysis Question 1
The r square value for lm( y ~ x1 * x2, data=exampleDF) is 0.8416 meaning that 84.16 percent of the variation in the data can be explained using this model.  Using this to predict NA values is reasonable. I am 84.16% confident it will valueable predictions for these missing Y values. 





# Linear Regression 2 [*Applied*]
```{r eval=FALSE}

var1 <- rnorm(1000, 0, 1)
var2 <- rnorm(1000, 0, 1)

random.fit<-lm(var1~var2)
summary(random.fit)
coef(random.fit)
```
Write your text and interpretation here

## Is the slope coeffecient significant?
No. It is -0.00752 which is nearly flat. There is not a clear linear segregaton of data. This is supported by an r squared value of 5.76e-05.

##How much variation does the model explain? Why is this? 
This model explains very little about the variation in the data.  The r squared value is 0.0000576 meaning that only 0.00576% of the data is explained by the model.


# Linear Regression 3 [*Applied*]
```{r eval=FALSE}
# The Manhattan Housing data contains missing values indicated by "0" 
# so we are using the argument na.strings="0" to treat them as missing values.
df <- read.csv("rollingsales_manhattan.csv", na.strings="0")

manhattanDF <- read.csv("C:/Users/Owned/Documents/MGMT6233/rollingsales_manhattan.csv", na.strings="0") #set for my wd

#log transformation
salePriceLog<-log(manhattanDF$SALE.PRICE)

#linear regression
neighborhood.fit<-lm(salePriceLog~manhattanDF$NEIGHBORHOOD)
borough.fit<-lm(salePriceLog~manhattanDF$BOROUGH)
block.fit<-lm(salePriceLog~manhattanDF$BLOCK)
zip.fit<-lm(salePriceLog~manhattanDF$ZIP.CODE)
yearBuilt.fit<-lm(salePriceLog~manhattanDF$YEAR.BUILT)
squareFeet<-lm(salePriceLog~manhattanDF$GROSS.SQUARE.FEET)
buildingClassTOS.fit<-lm(salePriceLog~manhattanDF$BUILDING.CLASS.AT.TIME.OF.SALE)
residential.fit<-lm(salePriceLog~manhattanDF$RESIDENTIAL.UNITS)
commercial.fit<-lm(salePriceLog~manhattanDF$COMMERCIAL.UNITS)

```

##Question 2 Comments and Analysis
The biggest predictor of price in this analysis was BUILDING.CLASS.AT.TIME.OF.SALE with an r-squared value of .5455  RESIDENTIAL.UNITS only had an r-squared value of 0.0901 suggesting that that isn't a
good predictor of sales price, however COMMERCIAL.UNITS had an r-squared value of .4659 suggesting that it is nearly as good of a predictor as BUILDING.CLASS.AT.TIME.OF.SALE. 
NEIGHBORHOOD, BOUROUGH, ZIP and BLOCK all had low r-squared values, as did YEAR.BUILT and GROSS.SQUARE.FEET. I would recommend looking for housing in areas with fewer properties zoned for
commercial use.

Why regression is approrpriate: Although a lot of variables did not fit well into a linear regression, both BUILDING.CLASS.AT.TIME.OF.SALE (.5455) and COMMERCIAL.UNITS(.4659) had high r-squared values. This means that the Building Class model explains 54% of the variation in the data and the Commercial Units model explains ~47% of the variation in the data.


Actions: actions that could be taken from this data would be to consider to look at the Building Class when considering the purchase of a property. Further actions could be taken to evaluate
interaction terms for things like square footage, and neighborhood,year build, etch. It could be that these areimportant factors as well, but that they just don't fit a linear model.

# Support-Vector Machines [*Applied*]
```{r eval=FALSE}
# install.packages("kernlab")
library(e1071)
library(kernlab)
data(spam)
dim(spam)
head(spam)

set.seed(02115)
sample <- sample( c(TRUE, FALSE), nrow(spam), replace=TRUE)
train <- spam[sample,]
test <- spam[!sample,]

#svm()
trainfit <- svm(type ~ ., data=train, kernel="linear", cost=.1, scale=FALSE)
svmPred<- predict(trainfit, test)
table(Predict=svmPred, Truth=test$type)





...

```

##question 4 comments and analyzis

The class error with cost=10 was 17.439%
Cost =10
Class Error = 17.439%

Truth
Predict   nonspam spam
  nonspam    1024   61
  spam        334  846
  

Can you improve the class error? Yes, by moving cost to .1 I was able to bring the Class Error down to 9.978%.

  Cost=.1
  Class Error=9.978%

Truth
Predict   nonspam spam
  nonspam    1285  153
  spam         73  754
  

I think it is easier to interperet the svm than the linear regression, especially when you build a table like the one above.  An svm just shows you the counts how how many predictions were right vs how many were wrong. With a linear regression, you can asses how well the data fits the model, but would have to do additional calculations to get quatifiable numbers like that found in an svm.
